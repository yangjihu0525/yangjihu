import streamlit as st
import yfinance as yf
import pandas as pd
import numpy as np
import plotly.graph_objects as go
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import StandardScaler
import requests
from bs4 import BeautifulSoup

# UI
st.title("ğŸ“ˆ AI ê¸°ë°˜ ì¢…í•© ì£¼ê°€ ì˜ˆì¸¡ ë¶„ì„ ì‹œìŠ¤í…œ")
ticker = st.text_input("ğŸ” ë¶„ì„í•  ì¢…ëª© ì½”ë“œ ì…ë ¥ (ì˜ˆ: AAPL, TSLA, 005930.KS)", "AAPL")

# ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
@st.cache_data
def load_data(ticker):
    data = yf.download(ticker, period="1y")
    data["SMA20"] = data["Close"].rolling(window=20).mean()
    data["SMA50"] = data["Close"].rolling(window=50).mean()
    return data

data = load_data(ticker)
st.subheader("ğŸ“Š ì£¼ê°€ ë° ì´ë™ í‰ê· ")
fig = go.Figure()
fig.add_trace(go.Scatter(x=data.index, y=data["Close"], name="ì¢…ê°€"))
fig.add_trace(go.Scatter(x=data.index, y=data["SMA20"], name="SMA 20"))
fig.add_trace(go.Scatter(x=data.index, y=data["SMA50"], name="SMA 50"))
st.plotly_chart(fig)

# ë¨¸ì‹ ëŸ¬ë‹ ì˜ˆì¸¡
st.subheader("ğŸ¤– ê°„ë‹¨í•œ ë¨¸ì‹ ëŸ¬ë‹ ê¸°ë°˜ ì˜ˆì¸¡ (Linear Regression)")

df = data.dropna().copy()
df["Tomorrow"] = df["Close"].shift(-1)
features = ["Close", "SMA20", "SMA50"]
X = df[features][:-1]
y = df["Tomorrow"][:-1]

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

model = LinearRegression()
model.fit(X_scaled, y)
tomorrow_pred = model.predict(scaler.transform([df[features].iloc[-1]]))[0]

st.metric("ğŸ“ˆ ë‚´ì¼ ì˜ˆìƒ ì¢…ê°€", f"{tomorrow_pred:.2f} USD")

# íˆíŠ¸ë§µ (ìƒê´€ ë¶„ì„)
st.subheader("ğŸ“Œ ì£¼ê°€ ê´€ë ¨ ì§€í‘œ ìƒê´€ê´€ê³„ íˆíŠ¸ë§µ")
correlation = df[["Close", "SMA20", "SMA50"]].corr()
sns.heatmap(correlation, annot=True, cmap="coolwarm")
st.pyplot(plt)

# ë‰´ìŠ¤ ë¶„ì„ (ê°„ë‹¨ ìš”ì•½)
st.subheader("ğŸ“° ìµœì‹  ë‰´ìŠ¤ ìš”ì•½")

def get_news_summary(ticker):
    search_url = f"https://news.google.com/search?q={ticker}"
    try:
        res = requests.get(search_url)
        soup = BeautifulSoup(res.text, "html.parser")
        articles = soup.select("article h3")
        return [a.get_text() for a in articles[:5]]
    except Exception as e:
        return ["ë‰´ìŠ¤ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."]

news = get_news_summary(ticker)
for i, article in enumerate(news):
    st.write(f"ğŸ—ï¸ {i+1}. {article}")

# ê²½ì œ ì§€í‘œ (ì˜ˆì‹œ: í™˜ìœ¨, ìœ ê°€ ë“±)
st.subheader("ğŸŒ ê°„ë‹¨í•œ ê¸€ë¡œë²Œ ê²½ì œ ì§€í‘œ (ìƒ˜í”Œ)")

st.write("âœ… í™˜ìœ¨ (USD/KRW): ì•½ 1,350ì› (ì˜ˆì‹œ)")
st.write("âœ… êµ­ì œ ìœ ê°€ (WTI): ì•½ 75 USD (ì˜ˆì‹œ)")
st.write("âœ… êµ­ê°€ ì„±ì¥ë¥ : 1.9% (ì˜ˆì‹œ)")

# ì¢…í•© ì„¤ëª…
st.markdown("""
---
ğŸ“Œ **ë¶„ì„ ìš”ì•½**  
- ê¸°ìˆ ì  ë¶„ì„ì— ë”°ë¼ SMA20ì´ SMA50ë³´ë‹¤ ìœ„ì— ìˆì„ ê²½ìš° ìƒìŠ¹ ì¶”ì„¸ì…ë‹ˆë‹¤.  
- ë¨¸ì‹ ëŸ¬ë‹ ì˜ˆì¸¡ì— ë”°ë¥´ë©´ ë‚´ì¼ ì£¼ê°€ëŠ” ì•½ê°„ ìƒìŠ¹í•  ê²ƒìœ¼ë¡œ ë³´ì…ë‹ˆë‹¤.  
- ìµœê·¼ ë‰´ìŠ¤ì—ì„œ í•´ë‹¹ ê¸°ì—… ê´€ë ¨ ê¸ì •/ë¶€ì • ì´ìŠˆë¥¼ íŒŒì•…í•˜ì„¸ìš”.  
- ê²½ì œ ì§€í‘œëŠ” ê¸°ì—… ê°€ì¹˜ì— ì¤‘ì¥ê¸°ì  ì˜í–¥ì„ ë¯¸ì¹©ë‹ˆë‹¤.

""")

